{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from scipy.stats import entropy, pearsonr, ttest_rel\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import ast\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load intrinsicality experiment data\n",
    "gpt_1 = pd.read_csv('../../results/Auction/Intrinsicality/gpt-4o_1.csv')\n",
    "gpt_2 = pd.read_csv('../../results/Auction/Intrinsicality/gpt-4o_2.csv')\n",
    "\n",
    "claude_3_5_1 = pd.read_csv('../../results/Auction/Intrinsicality/claude-3-5_1.csv')\n",
    "claude_3_5_2 = pd.read_csv('../../results/Auction/Intrinsicality/claude-3-5_2.csv')\n",
    "\n",
    "claude_3_7_1 = pd.read_csv('../../results/Auction/Intrinsicality/claude-3-7_1.csv')\n",
    "claude_3_7_2 = pd.read_csv('../../results/Auction/Intrinsicality/claude-3-7_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load instruction experiment data (risk preferences)\n",
    "claude_risk_seek_3_5 = pd.read_csv('../../results/Auction/Instruction/claude-3-5-seek.csv')\n",
    "claude_risk_averse_3_5 = pd.read_csv('../../results/Auction/Instruction/claude-3-5-averse.csv')\n",
    "claude_risk_seek_3_7 = pd.read_csv('../../results/Auction/Instruction/claude-3-7-seek.csv')\n",
    "claude_risk_averse_3_7 = pd.read_csv('../../results/Auction/Instruction/claude-3-7-averse.csv')\n",
    "gpt_risk_seek = pd.read_csv('../../results/Auction/Instruction/gpt-4o-seek.csv')\n",
    "gpt_risk_averse = pd.read_csv('../../results/Auction/Instruction/gpt-4o-averse.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_prepare_data(df_list, model_name):\n",
    "    \"\"\"Clean and standardize data format for analysis.\"\"\"\n",
    "    for df in df_list:\n",
    "        df.loc[:, \"profit\"] = df[\"profit_llm\"] if \"profit_llm\" in df.columns else df[\"profit\"]\n",
    "        df.loc[:, \"reserve_price\"] = df[\"reserve_price_llm\"] if \"reserve_price_llm\" in df.columns else df[\"reserve_price\"]\n",
    "        df.loc[:, \"round\"] = df.index % 60 + 1\n",
    "        df.loc[:, \"model\"] = model_name\n",
    "        df.rename(columns={\"Bidder Group\": \"bidder_group\"}, inplace=True)\n",
    "        if \"profit_llm\" in df.columns and \"reserve_price_llm\" in df.columns:\n",
    "            df.drop(columns=[\"profit_llm\", \"reserve_price_llm\"], inplace=True)\n",
    "\n",
    "# Clean and prepare all datasets\n",
    "clean_and_prepare_data([gpt_1, gpt_2], \"gpt-4o\")\n",
    "clean_and_prepare_data([claude_3_5_1, claude_3_5_2], \"claude-3-5\")\n",
    "clean_and_prepare_data([claude_3_7_1, claude_3_7_2], \"claude-3-7\")\n",
    "clean_and_prepare_data([gpt_risk_averse, gpt_risk_seek], \"gpt-4o\")\n",
    "clean_and_prepare_data([claude_risk_averse_3_5, claude_risk_seek_3_5], \"claude-3-5\")\n",
    "clean_and_prepare_data([claude_risk_averse_3_7, claude_risk_seek_3_7], \"claude-3-7\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add risk preference labels\n",
    "claude_risk_seek_3_5['risk'] = 'seeking'\n",
    "claude_risk_averse_3_5['risk'] = 'averse'\n",
    "claude_risk_seek_3_7['risk'] = 'seeking'\n",
    "claude_risk_averse_3_7['risk'] = 'averse'\n",
    "gpt_risk_seek['risk'] = 'seeking'\n",
    "gpt_risk_averse['risk'] = 'averse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load human experiment data\n",
    "human = pd.read_csv('../../human_experiment/auction_human_data.csv')\n",
    "\n",
    "human = human.rename(columns={\"myProfit\": \"profit\", \"rPrice\": \"reserve_price\", \"Bidder Group\": \"bidder_group\", \"newBids\": \"bids\"})\n",
    "human[\"round\"] = human.index % 60 + 1\n",
    "human[\"model\"] = \"human\"\n",
    "\n",
    "bid_info = human[['bidder_group', 'numBidders', 'highBid', 'round', 'bids']]\n",
    "bid_info.rename(columns={'numBidders': 'num_bidder'}, inplace=True)\n",
    "\n",
    "human = human[[\"bidder_group\",\"profit\", \"reserve_price\", \"round\", \"model\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine intrinsicality datasets\n",
    "llm_datasets = {\n",
    "    \"gpt-4o\": gpt_1,\n",
    "    \"claude-3-5\": claude_3_5_1,\n",
    "    \"claude-3-7\": claude_3_7_1\n",
    "}\n",
    "\n",
    "combined_df = pd.concat(llm_datasets.values(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and merge bidder profiles\n",
    "profiles = pd.read_excel('../profile_generation/umich_undergraduate_profiles.xlsx')\n",
    "profiles['stem'] = profiles['stem'].fillna(0)\n",
    "profiles[\"bidder_group\"] = profiles[\"id\"].apply(lambda x: f\"S.{int(x[1:])}\")\n",
    "\n",
    "# Merge profiles with LLM data\n",
    "combined_df = combined_df.merge(profiles, on=\"bidder_group\")\n",
    "\n",
    "combined_df = pd.concat([combined_df, human], ignore_index=True)\n",
    "combined_df = combined_df.merge(bid_info, on=[\"bidder_group\", \"round\"]).sort_values([\"model\", \"bidder_group\", \"round\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_bid_prices(bid_prices_str, return_second_only=False):\n",
    "    \"\"\"\n",
    "    Parse bid_prices string to get highest and second highest bids.\n",
    "    \n",
    "    Args:\n",
    "        bid_prices_str: String or list representation of bid prices\n",
    "        return_second_only: If True, return only second highest bid (for compatibility)\n",
    "    \n",
    "    Returns:\n",
    "        tuple (highest, second_highest) or float (second_highest only)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if pd.isna(bid_prices_str) or bid_prices_str == '':\n",
    "            return 0 if return_second_only else (0, 0)\n",
    "        \n",
    "        if isinstance(bid_prices_str, str):\n",
    "            # Try to parse as list first\n",
    "            try:\n",
    "                bids = ast.literal_eval(bid_prices_str)\n",
    "            except:\n",
    "                # Handle regex pattern format\n",
    "                numbers = re.findall(r'\\d+\\.?\\d*', str(bid_prices_str))\n",
    "                bids = [float(x) for x in numbers]\n",
    "        elif isinstance(bid_prices_str, list):\n",
    "            bids = bid_prices_str\n",
    "        else:\n",
    "            return 0 if return_second_only else (0, 0)\n",
    "        \n",
    "        if len(bids) == 0:\n",
    "            return 0 if return_second_only else (0, 0)\n",
    "        elif len(bids) == 1:\n",
    "            return bids[0] if return_second_only else (bids[0], bids[0])\n",
    "        else:\n",
    "            sorted_bids = sorted(bids, reverse=True)\n",
    "            if return_second_only:\n",
    "                return sorted_bids[1]\n",
    "            else:\n",
    "                return sorted_bids[0], sorted_bids[1]\n",
    "    except:\n",
    "        return 0 if return_second_only else (0, 0)\n",
    "\n",
    "def rp_entropy(series):\n",
    "    \"\"\"Calculate entropy for reserve price series.\"\"\"\n",
    "    counts = np.bincount(series.astype(int))\n",
    "    probs = counts[counts > 0] / counts.sum()\n",
    "    return entropy(probs, base=2)\n",
    "\n",
    "def extract_bid_prices(bid_string: str):\n",
    "    \"\"\"Extract bid prices from string using regex pattern.\"\"\"\n",
    "    return [int(x) for x in re.findall(r'd:(\\d+)', bid_string)]\n",
    "\n",
    "def analyze_rprice_bidder_correlation(data, rprice_col='reserve_price', bidder_col='num_bidder'):\n",
    "    \"\"\"\n",
    "    Analyze correlation between reserve price and number of bidders.\n",
    "    Returns correlation type and details.\n",
    "    \"\"\"\n",
    "    # Remove any missing values\n",
    "    clean_data = data[[rprice_col, bidder_col]].dropna()\n",
    "    \n",
    "    if len(clean_data) < 10:  # minimum data points\n",
    "        return 'Insufficient Data'\n",
    "    \n",
    "    rprice = clean_data[rprice_col]\n",
    "    bidders = clean_data[bidder_col]\n",
    "    \n",
    "    # Calculate overall linear correlation\n",
    "    try:\n",
    "        linear_corr, linear_p = pearsonr(rprice, bidders)\n",
    "    except:\n",
    "        return 'Cannot calculate'\n",
    "    \n",
    "    # Test for independence above different thresholds\n",
    "    unique_bidder_counts = sorted(bidders.unique())\n",
    "    \n",
    "    best_threshold = None\n",
    "    best_independence_score = 0\n",
    "    \n",
    "    # Test different thresholds\n",
    "    for threshold in unique_bidder_counts[:-1]:\n",
    "        above_threshold = clean_data[clean_data[bidder_col] > threshold]\n",
    "        \n",
    "        if len(above_threshold) >= 5:  # Need minimum observations above threshold\n",
    "            try:\n",
    "                above_corr, above_p = pearsonr(above_threshold[rprice_col], above_threshold[bidder_col])\n",
    "                # Independence score: closer to 0 correlation and non-significant p-value\n",
    "                independence_score = (1 - abs(above_corr)) * (1 if above_p > 0.05 else 0.5)\n",
    "                \n",
    "                if independence_score > best_independence_score:\n",
    "                    best_independence_score = independence_score\n",
    "                    best_threshold = threshold\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    # Determine correlation type\n",
    "    if linear_corr > 0.3 and linear_p < 0.05:\n",
    "        if best_threshold is not None and best_independence_score > 0.7:\n",
    "            return f'Linear+ then indep>{best_threshold}'\n",
    "        else:\n",
    "            return f'Linear positive (r={linear_corr:.2f})'\n",
    "    elif best_threshold is not None and best_independence_score > 0.7:\n",
    "        return f'Independent >{best_threshold} bidders'\n",
    "    elif abs(linear_corr) < 0.2:\n",
    "        return f'Independent (r={linear_corr:.2f})'\n",
    "    else:\n",
    "        return f'Weak pattern (r={linear_corr:.2f})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_comprehensive_metrics(df, include_human_ks=True, group_by_risk=False):\n",
    "    \"\"\"\n",
    "    Calculate comprehensive metrics for reserve price analysis.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with reserve price data\n",
    "        include_human_ks: Whether to calculate KS distance to human baseline\n",
    "        group_by_risk: Whether to group by risk preference (for instruction experiments)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with comprehensive metrics\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Determine grouping columns\n",
    "    if group_by_risk and 'risk' in df.columns:\n",
    "        group_cols = ['model', 'risk']\n",
    "        # Get unique model-risk combinations\n",
    "        groups = df.groupby(group_cols).size().reset_index()\n",
    "    else:\n",
    "        group_cols = ['model']\n",
    "        # Get unique models\n",
    "        groups = df['model'].unique()\n",
    "        groups = pd.DataFrame({'model': groups})\n",
    "    \n",
    "    # Get human baseline for KS distance comparison if needed\n",
    "    if include_human_ks:\n",
    "        human_rprice = df[df['model'] == 'human']['reserve_price'].values\n",
    "    \n",
    "    for _, group in groups.iterrows():\n",
    "        if group_by_risk and 'risk' in df.columns:\n",
    "            model, risk_type = group['model'], group['risk']\n",
    "            model_data = df[(df['model'] == model) & (df['risk'] == risk_type)]\n",
    "            source_label = f\"{model} ({risk_type})\" if risk_type != 'Intrinsicality' else model\n",
    "        else:\n",
    "            model = group['model']\n",
    "            model_data = df[df['model'] == model]\n",
    "            source_label = model\n",
    "        \n",
    "        if len(model_data) == 0:\n",
    "            continue\n",
    "            \n",
    "        rprice_data = model_data['reserve_price'].values\n",
    "        \n",
    "        # Basic statistics\n",
    "        mean_rprice = rprice_data.mean()\n",
    "        std_rprice = rprice_data.std()\n",
    "        \n",
    "        # Entropy calculation\n",
    "        entropy_val = rp_entropy(model_data['reserve_price'])\n",
    "        \n",
    "        # Sale through rate and premium capture rate \n",
    "        if 'sale' in model_data.columns:\n",
    "            sale_through_rate = model_data['sale'].mean()\n",
    "        else:\n",
    "            sale_through_rate = np.nan\n",
    "            \n",
    "        if 'premium_capture' in model_data.columns:\n",
    "            premium_capture_rate = model_data['premium_capture'].mean()\n",
    "        else:\n",
    "            premium_capture_rate = np.nan\n",
    "        \n",
    "        # KS distance (only for AI models, not human)\n",
    "        if include_human_ks and model != 'human' and len(human_rprice) > 0:\n",
    "            ks_distance = stats.ks_2samp(rprice_data, human_rprice).statistic\n",
    "        else:\n",
    "            ks_distance = 0.0 if model == 'human' else np.nan\n",
    "        \n",
    "        # rPrice-Bidder correlation analysis\n",
    "        bidder_col = 'num_bidder' if 'num_bidder' in model_data.columns else 'bidder_num'\n",
    "        if bidder_col in model_data.columns:\n",
    "            correlation_pattern = analyze_rprice_bidder_correlation(model_data, 'reserve_price', bidder_col)\n",
    "        else:\n",
    "            correlation_pattern = 'No bidder data'\n",
    "        \n",
    "        result = {\n",
    "            'Source': source_label,\n",
    "            'Mean': round(mean_rprice, 3),\n",
    "            'Std': round(std_rprice, 3), \n",
    "            'Entropy': round(entropy_val, 3),\n",
    "            'rPrice-Bidder Correlation': correlation_pattern\n",
    "        }\n",
    "\n",
    "        if not np.isnan(sale_through_rate):\n",
    "            result['Sale Through Rate'] = round(sale_through_rate, 3)\n",
    "        if not np.isnan(premium_capture_rate):\n",
    "            result['Premium Capture Rate'] = round(premium_capture_rate, 3)\n",
    "        if include_human_ks:\n",
    "            result['KS Distance to Human'] = round(ks_distance, 3) if not np.isnan(ks_distance) and model != 'human' else ('N/A' if model == 'human' else round(ks_distance, 3))\n",
    "        \n",
    "        # Add risk type for risk experiments\n",
    "        if group_by_risk and 'risk' in df.columns:\n",
    "            result['style'] = risk_type\n",
    "            \n",
    "        results.append(result)\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_rprice_bidder_correlation(data, rprice_col='reserve_price', bidder_col='num_bidder'):\n",
    "    \"\"\"\n",
    "    Analyze correlation between reserve price and number of bidders.\n",
    "    Returns correlation type and details.\n",
    "    \"\"\"\n",
    "    # Remove any missing values\n",
    "    clean_data = data[[rprice_col, bidder_col]].dropna()\n",
    "    \n",
    "    if len(clean_data) < 10:  # Need minimum data points\n",
    "        return 'Insufficient Data'\n",
    "    \n",
    "    rprice = clean_data[rprice_col]\n",
    "    bidders = clean_data[bidder_col]\n",
    "    \n",
    "    # Calculate overall linear correlation\n",
    "    try:\n",
    "        linear_corr, linear_p = pearsonr(rprice, bidders)\n",
    "    except:\n",
    "        return 'Cannot calculate'\n",
    "    \n",
    "    # Test for independence above different thresholds\n",
    "    unique_bidder_counts = sorted(bidders.unique())\n",
    "    \n",
    "    best_threshold = None\n",
    "    best_independence_score = 0\n",
    "    \n",
    "    # Test different thresholds\n",
    "    for threshold in unique_bidder_counts[:-1]:\n",
    "        above_threshold = clean_data[clean_data[bidder_col] > threshold]\n",
    "        \n",
    "        if len(above_threshold) >= 5:  # Need minimum observations above threshold\n",
    "            try:\n",
    "                above_corr, above_p = pearsonr(above_threshold[rprice_col], above_threshold[bidder_col])\n",
    "                # Independence score: closer to 0 correlation and non-significant p-value\n",
    "                independence_score = (1 - abs(above_corr)) * (1 if above_p > 0.05 else 0.5)\n",
    "                \n",
    "                if independence_score > best_independence_score:\n",
    "                    best_independence_score = independence_score\n",
    "                    best_threshold = threshold\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    # Determine correlation type\n",
    "    if linear_corr > 0.3 and linear_p < 0.05:\n",
    "        if best_threshold is not None and best_independence_score > 0.7:\n",
    "            return f'Linear+ then indep>{best_threshold}'\n",
    "        else:\n",
    "            return f'Linear positive (r={linear_corr:.2f})'\n",
    "    elif best_threshold is not None and best_independence_score > 0.7:\n",
    "        return f'Independent >{best_threshold} bidders'\n",
    "    elif abs(linear_corr) < 0.2:\n",
    "        return f'Independent (r={linear_corr:.2f})'\n",
    "    else:\n",
    "        return f'Weak pattern (r={linear_corr:.2f})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process bid information\n",
    "combined_df['bid_price_list'] = combined_df['bids'].apply(extract_bid_prices)\n",
    "combined_df['second_highest_bid'] = combined_df['bid_price_list'].apply(lambda x: sorted(x)[-2] if len(x) > 1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sale and premium capture metrics\n",
    "combined_df['sale'] = combined_df['reserve_price'] <= combined_df['highBid']\n",
    "combined_df['premium_capture'] = (combined_df['reserve_price'] <= combined_df['highBid']) & (combined_df['reserve_price'] > combined_df['second_highest_bid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rates by bidder group\n",
    "sale_rate = combined_df.groupby(['model', 'bidder_group'])['sale'].mean().reset_index()\n",
    "premium_capture_rate = combined_df.groupby(['model', 'bidder_group'])['premium_capture'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reserve Price Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_segment(round_num):\n",
    "    \"\"\"Create time segments for temporal analysis.\"\"\"\n",
    "    if round_num <= 20:\n",
    "        return '0-20'\n",
    "    elif round_num <= 40:\n",
    "        return '21-40'\n",
    "    else:\n",
    "        return '41-60'\n",
    "\n",
    "def linear_regression_analysis(y, x):\n",
    "    \"\"\"Perform linear regression and return coefficient, p-value, and significance.\"\"\"\n",
    "    try:\n",
    "        if len(x) > 2 and len(y) > 2 and x.var() > 0 and y.var() > 0:\n",
    "            X = sm.add_constant(x)\n",
    "            model = sm.OLS(y, X).fit()\n",
    "            \n",
    "            coef = model.params.iloc[1]  # Coefficient for x variable\n",
    "            p_value = model.pvalues.iloc[1]  # P-value for x variable\n",
    "            \n",
    "            # Determine significance level\n",
    "            if p_value < 0.001:\n",
    "                significance = '***'\n",
    "            elif p_value < 0.01:\n",
    "                significance = '**'\n",
    "            elif p_value < 0.05:\n",
    "                significance = '*'\n",
    "            else:\n",
    "                significance = ''\n",
    "                \n",
    "            return coef, p_value, significance\n",
    "        else:\n",
    "            return np.nan, np.nan, ''\n",
    "    except:\n",
    "        return np.nan, np.nan, ''\n",
    "\n",
    "# Add time segments to data\n",
    "combined_df['time_segment'] = combined_df['round'].apply(create_time_segment)\n",
    "\n",
    "# Temporal analysis by model and time segment\n",
    "def analyze_temporal_patterns(df, models_to_analyze=None):\n",
    "    \"\"\"Analyze temporal patterns in reserve pricing.\"\"\"\n",
    "    if models_to_analyze is None:\n",
    "        models_to_analyze = df['model'].unique()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for agent_type in models_to_analyze:\n",
    "        for time_seg in ['0-20', '21-40', '41-60']:\n",
    "            segment_data = df[(df['model'] == agent_type) & (df['time_segment'] == time_seg)]\n",
    "            \n",
    "            if len(segment_data) > 0:\n",
    "                # Basic statistics\n",
    "                avg_rprice = segment_data['reserve_price'].mean()\n",
    "                std_rprice = segment_data['reserve_price'].std()\n",
    "                \n",
    "                # Linear regression analyses\n",
    "                coef_round, p_round, sig_round = linear_regression_analysis(\n",
    "                    segment_data['reserve_price'], segment_data['round'])\n",
    "                \n",
    "                # Check if bidder number column exists\n",
    "                bidder_col = None\n",
    "                for col in ['num_bidder', 'bidder_num']:\n",
    "                    if col in segment_data.columns:\n",
    "                        bidder_col = col\n",
    "                        break\n",
    "                \n",
    "                if bidder_col:\n",
    "                    coef_bidnum, p_bidnum, sig_bidnum = linear_regression_analysis(\n",
    "                        segment_data['reserve_price'], segment_data[bidder_col])\n",
    "                else:\n",
    "                    coef_bidnum, p_bidnum, sig_bidnum = np.nan, np.nan, ''\n",
    "                \n",
    "                results.append({\n",
    "                    'Agent_Type': agent_type,\n",
    "                    'Time_Segment': time_seg,\n",
    "                    'Avg_Reserve_Price': round(avg_rprice, 2),\n",
    "                    'Std_Reserve_Price': round(std_rprice, 2),\n",
    "                    'Coef_rPrice_Round': round(coef_round, 4) if not np.isnan(coef_round) else np.nan,\n",
    "                    'P_val_Round': round(p_round, 4) if not np.isnan(p_round) else np.nan,\n",
    "                    'Sig_Round': sig_round,\n",
    "                    'Coef_rPrice_BidNum': round(coef_bidnum, 4) if not np.isnan(coef_bidnum) else np.nan,\n",
    "                    'P_val_BidNum': round(p_bidnum, 4) if not np.isnan(p_bidnum) else np.nan,\n",
    "                    'Sig_BidNum': sig_bidnum,\n",
    "                    'Count': len(segment_data)\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Run temporal analysis\n",
    "temporal_results = analyze_temporal_patterns(combined_df)\n",
    "print(\"Temporal Analysis Results:\")\n",
    "print(temporal_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidder Response Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_literature_benchmarks():\n",
    "    \"\"\"Plot literature benchmarks for reserve price vs number of bidders.\"\"\"\n",
    "    # Literature data\n",
    "    x = [1, 4, 7, 10]\n",
    "    davis = [18.4, 29.5, 38.7, 48.2]\n",
    "    wisconsin = [19.2, 25.0, 37.8, 45.5]\n",
    "    michigan = [14.8, 24.3, 32.9, 39.5]\n",
    "\n",
    "    data = {\n",
    "        'num_bidder': x * 3,\n",
    "        'reserve_price': davis + wisconsin + michigan,\n",
    "        'model': ['Davis et al. (2011)'] * 4 + ['Wisconsin'] * 4 + ['Michigan'] * 4\n",
    "    }\n",
    "    literature_df = pd.DataFrame(data)\n",
    "\n",
    "    # Plot styling\n",
    "    marker_style = {\n",
    "        'Davis et al. (2011)': 's',\n",
    "        'Wisconsin': '^',\n",
    "        'Michigan': 'X'\n",
    "    }\n",
    "    color_style = {\n",
    "        'Davis et al. (2011)': (57/255, 81/255, 162/255),\n",
    "        'Wisconsin': (253/255, 185/255, 107/255),\n",
    "        'Michigan': (236/255, 93/255, 59/255)\n",
    "    }\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5, 4))\n",
    "    sns.lineplot(\n",
    "        data=literature_df,\n",
    "        x='num_bidder', y='reserve_price',\n",
    "        hue='model', style='model',\n",
    "        markers=marker_style, dashes=False,\n",
    "        palette=color_style, ax=ax, linewidth=2.5\n",
    "    )\n",
    "\n",
    "    ax.set_xticks([1, 4, 7, 10])\n",
    "    ax.set_xlabel(\"Number of Bidders\")\n",
    "    ax.set_ylabel(\"Reserve Price\")\n",
    "    ax.spines[['top', 'right']].set_visible(False)\n",
    "    ax.legend(title=\"\", frameon=False, fontsize=9)\n",
    "    fig.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "# Create literature benchmark plot\n",
    "lit_fig, lit_ax = plot_literature_benchmarks()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_llm_vs_human_bidder_response(df):\n",
    "    \"\"\"Plot LLM vs Human reserve price response to number of bidders.\"\"\"\n",
    "    # Check if bidder data is available\n",
    "    bidder_col = None\n",
    "    for col in ['num_bidder', 'bidder_num']:\n",
    "        if col in df.columns:\n",
    "            bidder_col = col\n",
    "            break\n",
    "    \n",
    "    if bidder_col is None:\n",
    "        print(\"No bidder data available for plotting\")\n",
    "        return None, None\n",
    "    \n",
    "    # Color scheme\n",
    "    colors = {\n",
    "        \"claude-3-5\": (57/255, 81/255, 162/255),\n",
    "        \"claude-3-7\": (114/255, 170/255, 207/255),\n",
    "        \"gpt-4o\": (253/255, 185/255, 107/255),\n",
    "        \"human\": (236/255, 93/255, 59/255)\n",
    "    }\n",
    "\n",
    "    legend_labels = {\n",
    "        'gpt-4o': 'GPT-4o',\n",
    "        'claude-3-5': 'Claude-3.5',\n",
    "        'claude-3-7': 'Claude-3.7', \n",
    "        'human': 'Human'\n",
    "    }\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    \n",
    "    # Plot lines for each model\n",
    "    available_models = df['model'].unique()\n",
    "    available_colors = {k: v for k, v in colors.items() if k in available_models}\n",
    "    \n",
    "    sns.lineplot(\n",
    "        data=df, \n",
    "        x=bidder_col, \n",
    "        y='reserve_price',\n",
    "        hue='model', \n",
    "        style='model', \n",
    "        markers=['o', 's', '^', 'X'][:len(available_models)],\n",
    "        dashes=False,\n",
    "        palette=available_colors, \n",
    "        ax=ax, \n",
    "        linewidth=2.5\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"Number of Bidders\")\n",
    "    ax.set_ylabel(\"Reserve Price\")\n",
    "    ax.spines[['top', 'right']].set_visible(False)\n",
    "    \n",
    "    # Update legend\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    new_labels = [legend_labels.get(label, label) for label in labels]\n",
    "    ax.legend(\n",
    "        handles=handles,\n",
    "        labels=new_labels,\n",
    "        title=\"\",\n",
    "        frameon=True,\n",
    "        fontsize=13,\n",
    "        framealpha=0.8,\n",
    "        facecolor='white'\n",
    "    )\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    return fig, ax\n",
    "\n",
    "# Create LLM vs Human comparison plot\n",
    "comparison_fig, comparison_ax = plot_llm_vs_human_bidder_response(combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk Preference Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine risk preference datasets\n",
    "combined_df_risk_seek = pd.concat([claude_risk_seek_3_5, claude_risk_seek_3_7, gpt_risk_seek], ignore_index=True)\n",
    "combined_df_risk_seek = combined_df_risk_seek.merge(profiles, on=\"bidder_group\")\n",
    "\n",
    "combined_df_risk_averse = pd.concat([claude_risk_averse_3_5, claude_risk_averse_3_7, gpt_risk_averse], ignore_index=True)\n",
    "combined_df_risk_averse = combined_df_risk_averse.merge(profiles, on=\"bidder_group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all risk and intrinsicality data\n",
    "risk_df = pd.concat([combined_df_risk_seek, combined_df_risk_averse, combined_df], ignore_index=True)\n",
    "risk_df['risk'] = risk_df['risk'].fillna('Intrinsicality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add time segments to risk data\n",
    "risk_df['time_segment'] = risk_df['round'].apply(create_time_segment)\n",
    "\n",
    "def analyze_risk_temporal_patterns(df):\n",
    "    \"\"\"Analyze temporal patterns in risk preference experiments.\"\"\"\n",
    "    # Summary by risk preference and time segment\n",
    "    time_risk_summary = df.groupby(['time_segment', 'risk'])['reserve_price'].agg(['mean', 'std', 'count']).round(2)\n",
    "    time_risk_summary.columns = ['Average Reserve Price', 'Standard Deviation', 'Count']\n",
    "    \n",
    "    # Detailed breakdown by model, time segment, and risk\n",
    "    detailed_summary = df.groupby(['model', 'time_segment', 'risk'])['reserve_price'].agg(['mean', 'std', 'count']).round(2)\n",
    "    detailed_summary.columns = ['Average Reserve Price', 'Standard Deviation', 'Count']\n",
    "    \n",
    "    return time_risk_summary, detailed_summary\n",
    "\n",
    "# Run risk temporal analysis\n",
    "risk_temporal_summary, risk_detailed_summary = analyze_risk_temporal_patterns(risk_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Consistency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelConsistencyAnalyzer:\n",
    "    \"\"\"Analyze consistency across multiple runs of the same model.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name, df_list):\n",
    "        self.model_name = model_name\n",
    "        self.df_list = df_list\n",
    "        self.num_models = len(df_list)\n",
    "        self.model_labels = [f\"{self.model_name}-{i+1}\" for i in range(self.num_models)]\n",
    "\n",
    "    def analyze_metric_consistency(self, metric):\n",
    "        \"\"\"Analyze consistency of a metric across model runs.\"\"\"\n",
    "        # Use bidder_group as grouping variable instead of Profile ID if available\n",
    "        group_col = \"bidder_group\" if \"bidder_group\" in self.df_list[0].columns else \"Profile ID\"\n",
    "        \n",
    "        metric_sums = {}\n",
    "        for label, df in zip(self.model_labels, self.df_list):\n",
    "            if group_col in df.columns:\n",
    "                metric_sums[label] = df.groupby(group_col)[metric].sum()\n",
    "            else:\n",
    "                metric_sums[label] = df[metric]\n",
    "\n",
    "        metric_df = pd.concat(metric_sums.values(), axis=1)\n",
    "        metric_df.columns = metric_sums.keys()\n",
    "\n",
    "        # Descriptive statistics\n",
    "        desc_stats = metric_df.describe()\n",
    "\n",
    "        # Correlation analysis\n",
    "        correlation_matrix = metric_df.corr()\n",
    "\n",
    "        return {\n",
    "            'data': metric_df,\n",
    "            'descriptive_stats': desc_stats,\n",
    "            'correlations': correlation_matrix\n",
    "        }\n",
    "\n",
    "    def perform_consistency_tests(self, metric):\n",
    "        \"\"\"Perform statistical tests for consistency.\"\"\"\n",
    "        group_col = \"bidder_group\" if \"bidder_group\" in self.df_list[0].columns else \"Profile ID\"\n",
    "        \n",
    "        if group_col not in self.df_list[0].columns:\n",
    "            # Fallback: use direct metric values\n",
    "            metric_data = [df[metric].values for df in self.df_list]\n",
    "        else:\n",
    "            metric_data = [df.groupby(group_col)[metric].sum().values for df in self.df_list]\n",
    "        \n",
    "        ttest_results = []\n",
    "        \n",
    "        for i in range(self.num_models):\n",
    "            for j in range(i + 1, self.num_models):\n",
    "                if len(metric_data[i]) == len(metric_data[j]):\n",
    "                    t_stat, p_value = ttest_rel(metric_data[i], metric_data[j])\n",
    "                    ttest_results.append({\n",
    "                        \"Comparison\": f\"{self.model_labels[i]} vs {self.model_labels[j]}\",\n",
    "                        \"t-statistic\": round(t_stat, 4),\n",
    "                        \"p-value\": round(p_value, 4)\n",
    "                    })\n",
    "\n",
    "        return pd.DataFrame(ttest_results)\n",
    "\n",
    "    def run_full_analysis(self):\n",
    "        \"\"\"Run complete consistency analysis.\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        # Analyze reserve price consistency\n",
    "        rp_analysis = self.analyze_metric_consistency(\"reserve_price\")\n",
    "        rp_tests = self.perform_consistency_tests(\"reserve_price\")\n",
    "        \n",
    "        results[\"reserve_price\"] = {\n",
    "            \"analysis\": rp_analysis,\n",
    "            \"tests\": rp_tests\n",
    "        }\n",
    "        \n",
    "        # Analyze profit consistency if available\n",
    "        if \"profit\" in self.df_list[0].columns:\n",
    "            profit_analysis = self.analyze_metric_consistency(\"profit\")\n",
    "            profit_tests = self.perform_consistency_tests(\"profit\")\n",
    "            \n",
    "            results[\"profit\"] = {\n",
    "                \"analysis\": profit_analysis,\n",
    "                \"tests\": profit_tests\n",
    "            }\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze GPT model consistency\n",
    "gpt_analyzer = ModelConsistencyAnalyzer(\"GPT\", [gpt_1, gpt_2])\n",
    "gpt_consistency_results = gpt_analyzer.run_full_analysis()\n",
    "\n",
    "print(\"GPT Model Consistency Analysis:\")\n",
    "print(\"Reserve Price T-tests:\")\n",
    "print(gpt_consistency_results[\"reserve_price\"][\"tests\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Claude model consistency\n",
    "claude_analyzer = ModelConsistencyAnalyzer(\"Claude\", [claude_3_7_1, claude_3_7_2])\n",
    "claude_consistency_results = claude_analyzer.run_full_analysis()\n",
    "\n",
    "print(\"Claude Model Consistency Analysis:\")\n",
    "print(\"Reserve Price T-tests:\")\n",
    "print(claude_consistency_results[\"reserve_price\"][\"tests\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk preference summary analysis\n",
    "def summarize_risk_preferences(df):\n",
    "    \"\"\"Create summary statistics for risk preference analysis.\"\"\"\n",
    "    # Filter for risk preference data only\n",
    "    risk_only_df = df[df['risk'].isin(['averse', 'seeking'])]\n",
    "    \n",
    "    if len(risk_only_df) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Summary by risk preference\n",
    "    risk_summary = risk_only_df.groupby('risk')['reserve_price'].agg(['mean', 'std', 'count']).round(2)\n",
    "    risk_summary.columns = ['Average Reserve Price', 'Standard Deviation', 'Count']\n",
    "    \n",
    "    # Detailed summary by model and risk\n",
    "    detailed_summary = risk_only_df.groupby(['model', 'risk'])['reserve_price'].agg(['mean', 'std', 'count']).round(2)\n",
    "    detailed_summary.columns = ['Average Reserve Price', 'Standard Deviation', 'Count']\n",
    "    \n",
    "    return risk_summary, detailed_summary\n",
    "\n",
    "# Generate risk preference summary\n",
    "risk_summaries = summarize_risk_preferences(risk_df)\n",
    "if risk_summaries:\n",
    "    risk_summary, detailed_risk_summary = risk_summaries\n",
    "    risk_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run comprehensive temporal regression analysis\n",
    "comprehensive_temporal_results = analyze_temporal_patterns(combined_df)\n",
    "\n",
    "# Add agent type categorization for LLM vs Human comparison\n",
    "combined_df['agent_type'] = combined_df['model'].apply(lambda x: 'Human' if x == 'human' else 'LLM')\n",
    "\n",
    "print(\"Temporal Analysis Results:\")\n",
    "print(comprehensive_temporal_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive metrics for intrinsicality experiments\n",
    "intrinsic_metrics = calculate_comprehensive_metrics(\n",
    "    combined_df, \n",
    "    include_human_ks=True, \n",
    "    group_by_risk=False\n",
    ")\n",
    "\n",
    "print(intrinsic_metrics.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive metrics for risk preference experiments\n",
    "risk_only_df = risk_df[risk_df['risk'].isin(['averse', 'seeking'])]\n",
    "\n",
    "if len(risk_only_df) > 0:\n",
    "    risk_metrics = calculate_comprehensive_metrics(\n",
    "        risk_only_df, \n",
    "        include_human_ks=True,  # Include human baseline for comparison\n",
    "        group_by_risk=True\n",
    "    )\n",
    "    \n",
    "    print(\"Risk Preference Experiment Comprehensive Metrics:\")\n",
    "    print(risk_metrics.to_string(index=False))\n",
    "else:\n",
    "    print(\"No risk preference data available for comprehensive analysis\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
